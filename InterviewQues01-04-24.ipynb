{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN4rk8sdOY4kJmlwfWTdSN4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pugazhendhij/PROMPT/blob/master/InterviewQues01-04-24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GPDShK-qx3p"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import tika\n",
        "import json\n",
        "from tika import parser\n",
        "openai_key = \"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\"\n",
        "organization_key = \"org-i1EAnwbqVcTX9b9O5yunvThu\"\n",
        "client = OpenAI(\n",
        "    organization='org-i1EAnwbqVcTX9b9O5yunvThu',\n",
        "    api_key = openai_key,\n",
        ")\n",
        "\n",
        "\n",
        "def openai_temperature(user_message):\n",
        "    completion = client.chat.completions.create(\n",
        "            model='gpt-3.5-turbo',\n",
        "            temperature=0,\n",
        "            top_p=0,\n",
        "            messages=user_message)\n",
        "    response = (completion.choices[0].message).content\n",
        "    print(\"@#@#@#@#@##@#@#@#@#@#@\",response)\n",
        "    if 'json' in response:\n",
        "        response = response.replace('json','')\n",
        "        response = json.loads(response)\n",
        "    token = completion.usage.total_tokens\n",
        "    return response,token\n",
        "\n",
        "def interview_prompt(role,count1,level,jobtitle,summary,output_format):\n",
        "    summary = summary if summary else ''\n",
        "    prompt = {\n",
        "        \"prompt_template\": \"Generate interview questions based on specific criteria.\",\n",
        "        \"instructions\": \"[no prose and should not be in string]\\n[Output only JSON] Using the information provided, construct a set of unique interview questions tailored to the interviewer's role, the job's requirements, and the candidate's profile. Additionally, provide optimal answers for each question. Your output must be in a structured JSON format that can be directly parsed using 'json.loads()' without errors.\",\n",
        "        \"input_fields\": {\n",
        "            \"role\": role,\n",
        "            \"count1\": count1,\n",
        "            \"level\": level,\n",
        "        },\n",
        "        \"output_requirements\": {\n",
        "            \"format\": \"JSON\",\n",
        "            \"summary\" : summary,\n",
        "            \"structure\": f\"Provide the output in the following JSON structure: {output_format} Replace placeholder text with the appropriate values based on the input fields.\",\n",
        "            \"example\": {\n",
        "            \"interviewer_role\": f'{jobtitle}',\n",
        "            \"questions\": [\n",
        "                {\n",
        "                \"question\": \"\",\n",
        "                \"priority\":\"High\",\n",
        "                \"level\":\"Easy\",\n",
        "                \"type\":\"General\",\n",
        "                \"answer\": \"\"\n",
        "                },\n",
        "                {\n",
        "                \"question\": \"\",\n",
        "                \"priority\":\"High\",\n",
        "                \"level\":\"Easy\",\n",
        "                \"type\":\"General\",\n",
        "                \"answer\": \"\"\n",
        "                }\n",
        "            ],\n",
        "            \"total_questions\": f'{count1}',\n",
        "            \"level\": f\"{level}\"\n",
        "            },\n",
        "            \"note\": f\"Ensure the 'questions' array contains a unique set of questions and answers equal to '{count1}', and the output JSON is correctly formatted for parsing.\"\n",
        "        }\n",
        "    }\n",
        "    return prompt\n",
        "\n",
        "chat_log = []\n",
        "job_title = ''\n",
        "summary = ''\n",
        "jd_input = ''\n",
        "can_input = ''\n",
        "jd_upload = f\"ChatGPT, please await further instructions. i will upload a job description {jd_input} and candidate profile {can_input}, you can proceed with any further tasks or questions. Refrain from parsing until further prompts given\"\n",
        "chat_log.append({\"role\":\"user\",\"content\":jd_upload})\n",
        "response,count_token = openai_temperature(chat_log) #1 -JD & profile uploaded\n",
        "\n",
        "table = []\n",
        "for x in table:\n",
        "    role = ''\n",
        "    count = x[\"count\"]\n",
        "    var = x[\"type\"]\n",
        "    level = x[\"level\"]\n",
        "    output_format = '{\"questions\":[\"question\":\"\",\"priority\":\"High/Medium/Low\",\"level\":\"Easy/Medium/Hard\",\"type\":\"Technical/Coding/General/Behavioral/IQ level\",\"answer\":\"optimal answer in single line\"]}'\n",
        "    user_message = interview_prompt(role,x[\"count\"],level,job_title,summary,output_format)\n",
        "    system = \"You are a helpful assistant. Provide the interview questions for candidates based on the provided criteria.\"\n",
        "    user_message = str(user_message)\n",
        "    chat_log.append({\"role\":\"system\",\"content\":system})\n",
        "    chat_log.append({\"role\":\"user\",\"content\":user_message})\n",
        "    print(\"Interview Question INPUT\\n\",chat_log)\n",
        "    system = \"You are a helpful assistant. Provide the interview questions for candidates based on the provided criteria.\"\n",
        "    response,count_token = openai_temperature(chat_log) #2 - Question Uploaded\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install openai\n",
        "!pip3 install tika"
      ],
      "metadata": {
        "id": "CfQ_KEBrsMPj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}